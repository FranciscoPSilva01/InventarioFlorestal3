{"file_contents":{"app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport io\nfrom utils.calculations import ForestryCalculator\nfrom utils.statistics import StatisticsAnalyzer\nfrom utils.report_generator import ReportGenerator\n\ndef detect_and_map_columns(df):\n    \"\"\"Detecta e mapeia automaticamente as colunas da planilha\"\"\"\n    df_original = df.copy()\n    df = df.copy()\n    df.columns = df.columns.str.strip()\n    \n    # Contar linhas iniciais\n    initial_rows = len(df)\n    st.write(f\"**Processamento iniciado com {initial_rows} linhas**\")\n    \n    mapping_results = []\n    new_columns = []\n    used_mappings = set()\n    \n    for i, col in enumerate(df.columns):\n        original_col = str(col).strip()\n        col_upper = original_col.upper()\n        mapped_name = None\n        \n        # Detectar coluna de numera√ß√£o das √°rvores\n        if ('N¬∞' in col_upper or col_upper in ['N', 'NO', 'NUM', 'NUMERO', 'N√öMERO']) and 'N¬∫ da √°rvore' not in used_mappings:\n            mapped_name = 'N¬∫ da √°rvore'\n            used_mappings.add('N¬∫ da √°rvore')\n        \n        # Detectar nome comum\n        elif 'NOME' in col_upper and 'COMUM' in col_upper and 'Nome comum' not in used_mappings:\n            mapped_name = 'Nome comum'\n            used_mappings.add('Nome comum')\n        \n        # Detectar nome cient√≠fico\n        elif 'NOME' in col_upper and ('CIENT√çFICO' in col_upper or 'CIENTIFICO' in col_upper) and 'Nome cient√≠fico' not in used_mappings:\n            mapped_name = 'Nome cient√≠fico'\n            used_mappings.add('Nome cient√≠fico')\n        \n        # Detectar CAP\n        elif 'CAP' in col_upper and 'CAP (cm)' not in used_mappings:\n            mapped_name = 'CAP (cm)'\n            used_mappings.add('CAP (cm)')\n        \n        # Detectar altura (HT)\n        elif ('HT' in col_upper or 'ALTURA' in col_upper) and 'HT (m)' not in used_mappings:\n            mapped_name = 'HT (m)'\n            used_mappings.add('HT (m)')\n        \n        # Se n√£o mapear ou j√° estiver usado, manter nome original\n        if mapped_name is None:\n            # Garantir nome √∫nico\n            base_name = original_col\n            counter = 1\n            while base_name in new_columns:\n                base_name = f\"{original_col}_{counter}\"\n                counter += 1\n            mapped_name = base_name\n            mapping_results.append(f\"‚Ä¢ '{original_col}' ‚Üí mantido como '{mapped_name}'\")\n        else:\n            mapping_results.append(f\"‚úì '{original_col}' ‚Üí '{mapped_name}'\")\n        \n        new_columns.append(mapped_name)\n    \n    # Aplicar novos nomes das colunas\n    df.columns = new_columns\n    st.write(f\"**Ap√≥s renomear colunas: {len(df)} linhas**\")\n    \n    # Criar coluna combinada de nomes se necess√°rio\n    if 'Nome comum' in df.columns and 'Nome cient√≠fico' in df.columns:\n        df['Nome comum/cient√≠fico'] = df['Nome comum'].astype(str) + ' / ' + df['Nome cient√≠fico'].astype(str)\n        mapping_results.append(\"‚úì Combinadas colunas de nomes\")\n    elif 'Nome comum' in df.columns:\n        df['Nome comum/cient√≠fico'] = df['Nome comum']\n        mapping_results.append(\"‚úì Usando nome comum como identifica√ß√£o\")\n    elif 'Nome cient√≠fico' in df.columns:\n        df['Nome comum/cient√≠fico'] = df['Nome cient√≠fico']\n        mapping_results.append(\"‚úì Usando nome cient√≠fico como identifica√ß√£o\")\n    \n    final_rows = len(df)\n    st.write(f\"**Processamento finalizado com {final_rows} linhas**\")\n    \n    # Verificar se alguma linha foi perdida\n    if final_rows < initial_rows:\n        st.error(f\"‚ùå PERDA DE DADOS: {initial_rows - final_rows} linhas foram removidas durante o mapeamento!\")\n    \n    # Mostrar resultados do mapeamento\n    st.success(\"Mapeamento de colunas realizado:\")\n    for result in mapping_results:\n        st.write(result)\n    \n    # Mostrar colunas finais\n    st.info(f\"Colunas finais: {list(df.columns)}\")\n    \n    return df\n\ndef main():\n    st.set_page_config(\n        page_title=\"Sistema de Invent√°rio Florestal\",\n        page_icon=\"üå≥\",\n        layout=\"wide\"\n    )\n    \n    st.title(\"üå≥ Sistema de Invent√°rio Florestal\")\n    st.markdown(\"Sistema para processamento e an√°lise de invent√°rios florestais\")\n    \n    # Initialize session state\n    if 'data_processed' not in st.session_state:\n        st.session_state.data_processed = False\n    if 'results_df' not in st.session_state:\n        st.session_state.results_df = None\n    if 'statistics' not in st.session_state:\n        st.session_state.statistics = None\n    if 'project_info' not in st.session_state:\n        st.session_state.project_info = None\n    if 'file_uploaded' not in st.session_state:\n        st.session_state.file_uploaded = False\n    if 'input_data' not in st.session_state:\n        st.session_state.input_data = None\n    \n    # Create tabs\n    tab1, tab2, tab3, tab4 = st.tabs([\"üìÇ Upload de Dados\", \"‚öôÔ∏è Processamento\", \"üìä Estat√≠sticas\", \"üìë Relat√≥rio\"])\n    \n    with tab1:\n        upload_data_tab()\n    \n    with tab2:\n        processing_tab()\n    \n    with tab3:\n        statistics_tab()\n    \n    with tab4:\n        report_tab()\n\ndef upload_data_tab():\n    st.header(\"üìÇ Upload de Dados de Campo\")\n    \n    col1, col2 = st.columns([1, 1])\n    \n    with col1:\n        st.subheader(\"Informa√ß√µes do Projeto\")\n        project_name = st.text_input(\"Nome do Projeto*\", key=\"project_name\")\n        num_plots = st.number_input(\"Quantidade de Parcelas*\", min_value=1, value=1, key=\"num_plots\")\n        \n        st.subheader(\"Dimens√µes da Parcela\")\n        plot_length = st.number_input(\"Comprimento da Parcela (m)*\", min_value=0.1, value=20.0, step=0.1, key=\"plot_length\")\n        plot_width = st.number_input(\"Largura da Parcela (m)*\", min_value=0.1, value=20.0, step=0.1, key=\"plot_width\")\n        \n        total_area = st.number_input(\"√Årea Total a ser Suprimida (ha)*\", min_value=0.01, value=1.0, step=0.01, key=\"total_area\")\n        form_factor = st.number_input(\"Fator de Forma (FF)*\", min_value=0.1, max_value=1.0, value=0.7, step=0.01, key=\"form_factor\")\n    \n    with col2:\n        st.subheader(\"Upload de Planilha\")\n        uploaded_file = st.file_uploader(\n            \"Selecione a planilha com dados de campo\",\n            type=['csv', 'xlsx'],\n            help=\"A planilha deve conter as colunas: UA, N¬∞, NOME COMUM, NOME CIENT√çFICO, CAP (cm), HT(m)\"\n        )\n        \n        if uploaded_file is not None:\n            try:\n                if uploaded_file.name.endswith('.csv'):\n                    df = pd.read_csv(uploaded_file)\n                else:\n                    df = pd.read_excel(uploaded_file)\n                \n                st.success(f\"Arquivo carregado com sucesso! {len(df)} registros encontrados na planilha original.\")\n                st.dataframe(df.head())\n                \n                # Mostrar informa√ß√µes detalhadas sobre os dados originais\n                st.info(f\"üìä Dados originais: {len(df)} linhas, {len(df.columns)} colunas\")\n                \n                # Verificar especificamente a coluna N¬∞ para contar √°rvores\n                tree_count_analysis = []\n                for col in df.columns:\n                    if 'N¬∞' in str(col).upper() or 'N' == str(col).upper():\n                        unique_trees = df[col].nunique()\n                        valid_entries = df[col].notna().sum()\n                        tree_count_analysis.append(f\"Coluna '{col}': {valid_entries} entradas v√°lidas, {unique_trees} √°rvores √∫nicas\")\n                        \n                        # Verificar se h√° n√∫meros duplicados\n                        duplicates = df[col].duplicated().sum()\n                        if duplicates > 0:\n                            tree_count_analysis.append(f\"  ‚ö†Ô∏è {duplicates} n√∫meros duplicados encontrados\")\n                        \n                        # Verificar valores vazios\n                        empty_values = df[col].isna().sum()\n                        if empty_values > 0:\n                            tree_count_analysis.append(f\"  ‚ö†Ô∏è {empty_values} valores vazios encontrados\")\n                \n                if tree_count_analysis:\n                    st.write(\"**An√°lise da contagem de √°rvores:**\")\n                    for analysis in tree_count_analysis:\n                        st.write(analysis)\n                \n                # Detectar automaticamente as colunas\n                df_processed = detect_and_map_columns(df)\n                \n                # Verificar se perdemos dados durante o processamento\n                if len(df_processed) < len(df):\n                    lost_rows = len(df) - len(df_processed)\n                    st.warning(f\"‚ö†Ô∏è Aten√ß√£o: {lost_rows} linhas foram removidas durante o processamento (provavelmente linhas vazias ou com dados inv√°lidos)\")\n                    \n                    # Mostrar quais linhas foram removidas\n                    st.write(\"**An√°lise de dados removidos:**\")\n                    original_indices = set(df.index)\n                    processed_indices = set(df_processed.index)\n                    removed_indices = original_indices - processed_indices\n                    \n                    if removed_indices:\n                        st.write(f\"Linhas removidas: {sorted(list(removed_indices))}\")\n                \n                # Salvar dados automaticamente\n                st.session_state.input_data = df_processed\n                st.session_state.file_uploaded = True\n                st.success(\"‚úÖ Planilha carregada e dados salvos automaticamente!\")\n                st.info(f\"üìä {len(df_processed)} √°rvores v√°lidas detectadas e prontas para processamento\")\n                \n                # Mostrar preview dos dados processados\n                st.subheader(\"Preview dos Dados Processados\")\n                st.dataframe(df_processed.head(), use_container_width=True)\n                \n                # Mostrar estat√≠sticas dos dados\n                st.subheader(\"Resumo dos Dados\")\n                col1, col2, col3 = st.columns(3)\n                with col1:\n                    st.metric(\"Total Original\", len(df))\n                with col2:\n                    st.metric(\"Total Processado\", len(df_processed))\n                with col3:\n                    if len(df_processed) < len(df):\n                        st.metric(\"Linhas Removidas\", len(df) - len(df_processed), delta=-(len(df) - len(df_processed)))\n                    else:\n                        st.metric(\"Linhas Removidas\", 0)\n                    \n            except Exception as e:\n                st.error(f\"Erro ao carregar o arquivo: {str(e)}\")\n    \n    # Process data button\n    if st.button(\"Processar Dados\", type=\"primary\"):\n        # Validate all required fields\n        errors = []\n        if not project_name:\n            errors.append(\"Nome do Projeto √© obrigat√≥rio\")\n        if num_plots < 1:\n            errors.append(\"Quantidade de Parcelas deve ser pelo menos 1\")\n        if plot_length <= 0 or plot_width <= 0:\n            errors.append(\"Dimens√µes da parcela devem ser positivas\")\n        if total_area <= 0:\n            errors.append(\"√Årea total deve ser positiva\")\n        if not (0.1 <= form_factor <= 1.0):\n            errors.append(\"Fator de Forma deve estar entre 0.1 e 1.0\")\n        if not st.session_state.file_uploaded or st.session_state.input_data is None:\n            errors.append(\"Nenhum arquivo foi carregado\")\n        \n        if errors:\n            for error in errors:\n                st.error(f\"‚ö†Ô∏è {error}\")\n        else:\n            # Store project information\n            plot_area = plot_length * plot_width / 10000  # Convert to hectares\n            total_sampled_area = plot_area * num_plots\n            sampling_percentage = (total_sampled_area / total_area) * 100\n            \n            project_info = {\n                'project_name': project_name,\n                'num_plots': num_plots,\n                'plot_length': plot_length,\n                'plot_width': plot_width,\n                'plot_area': plot_area,\n                'total_area': total_area,\n                'total_sampled_area': total_sampled_area,\n                'sampling_percentage': sampling_percentage,\n                'form_factor': form_factor\n            }\n            \n            st.session_state.project_info = project_info\n            \n            # Process calculations\n            calculator = ForestryCalculator()\n            results_df = calculator.process_data(st.session_state.input_data, form_factor, plot_area)\n            st.session_state.results_df = results_df\n            \n            # Calculate statistics\n            analyzer = StatisticsAnalyzer()\n            statistics = analyzer.calculate_statistics(results_df, project_info)\n            st.session_state.statistics = statistics\n            \n            st.session_state.data_processed = True\n            st.success(\"‚úÖ Dados processados com sucesso!\")\n            st.rerun()\n\ndef processing_tab():\n    st.header(\"‚öôÔ∏è Processamento dos Dados\")\n    \n    if not st.session_state.data_processed:\n        st.warning(\"‚ö†Ô∏è Primeiro fa√ßa o upload e processamento dos dados na aba 'Upload de Dados'\")\n        return\n    \n    st.subheader(\"Informa√ß√µes do Projeto\")\n    project_info = st.session_state.project_info\n    \n    col1, col2, col3 = st.columns(3)\n    with col1:\n        st.metric(\"Projeto\", project_info['project_name'])\n        st.metric(\"Parcelas\", project_info['num_plots'])\n    with col2:\n        st.metric(\"√Årea por Parcela\", f\"{project_info['plot_area']:.4f} ha\")\n        st.metric(\"√Årea Total Amostrada\", f\"{project_info['total_sampled_area']:.4f} ha\")\n    with col3:\n        st.metric(\"√Årea de Supress√£o\", f\"{project_info['total_area']:.2f} ha\")\n        st.metric(\"% Amostrada\", f\"{project_info['sampling_percentage']:.2f}%\")\n    \n    st.subheader(\"C√°lculos por √Årvore\")\n    results_df = st.session_state.results_df\n    \n    # Display results table\n    st.dataframe(\n        results_df.style.format({\n            'CAP (cm)': '{:.2f}',\n            'HT (m)': '{:.2f}',\n            'DAP (cm)': '{:.4f}',\n            'VT (m¬≥)': '{:.4f}',\n            'VT (m¬≥/ha)': '{:.4f}',\n            'VT (st/ha)': '{:.4f}'\n        }),\n        use_container_width=True\n    )\n    \n    # Summary statistics\n    st.subheader(\"Resumo dos C√°lculos\")\n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        st.metric(\"Total de √Årvores\", len(results_df))\n        st.metric(\"Volume Total (m¬≥)\", f\"{results_df['VT (m¬≥)'].sum():.4f}\")\n    \n    with col2:\n        st.metric(\"Volume M√©dio (m¬≥/ha)\", f\"{results_df['VT (m¬≥/ha)'].mean():.4f}\")\n        st.metric(\"Volume Total (m¬≥/ha)\", f\"{results_df['VT (m¬≥/ha)'].sum():.4f}\")\n    \n    with col3:\n        st.metric(\"Volume M√©dio (st/ha)\", f\"{results_df['VT (st/ha)'].mean():.4f}\")\n        st.metric(\"Volume Total (st/ha)\", f\"{results_df['VT (st/ha)'].sum():.4f}\")\n    \n    with col4:\n        st.metric(\"DAP M√©dio (cm)\", f\"{results_df['DAP (cm)'].mean():.4f}\")\n        st.metric(\"Altura M√©dia (m)\", f\"{results_df['HT (m)'].mean():.2f}\")\n\ndef statistics_tab():\n    st.header(\"üìä Estat√≠sticas e Precis√£o\")\n    \n    if not st.session_state.data_processed:\n        st.warning(\"‚ö†Ô∏è Primeiro fa√ßa o upload e processamento dos dados na aba 'Upload de Dados'\")\n        return\n    \n    statistics = st.session_state.statistics\n    \n    # Precision alert\n    if statistics['sampling_error'] > 20:\n        st.error(\"‚ö†Ô∏è Amostragem n√£o atingiu a precis√£o desejada (erro > 20%). Recomendado aumentar o n√∫mero de parcelas.\")\n    else:\n        st.success(\"‚úÖ Amostragem atingiu a precis√£o desejada (erro ‚â§ 20%).\")\n    \n    # Statistical metrics\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.subheader(\"Estat√≠sticas Descritivas\")\n        st.metric(\"M√©dia (m¬≥/ha)\", f\"{statistics['mean']:.4f}\")\n        st.metric(\"Vari√¢ncia\", f\"{statistics['variance']:.4f}\")\n        st.metric(\"Desvio Padr√£o\", f\"{statistics['std_dev']:.4f}\")\n        st.metric(\"Coeficiente de Varia√ß√£o\", f\"{statistics['cv']:.2f}%\")\n    \n    with col2:\n        st.subheader(\"Precis√£o da Amostragem\")\n        st.metric(\"Erro Amostral\", f\"{statistics['sampling_error']:.2f}%\")\n        st.metric(\"Limite Inferior IC 90%\", f\"{statistics['ci_lower']:.4f}\")\n        st.metric(\"Limite Superior IC 90%\", f\"{statistics['ci_upper']:.4f}\")\n        st.metric(\"Erro Padr√£o\", f\"{statistics['standard_error']:.4f}\")\n    \n    # Volume estimates\n    st.subheader(\"Estimativas de Volume para √Årea Total\")\n    project_info = st.session_state.project_info\n    \n    col1, col2, col3 = st.columns(3)\n    with col1:\n        volume_estimate = statistics['mean'] * project_info['total_area']\n        st.metric(\"Volume Estimado (m¬≥)\", f\"{volume_estimate:.2f}\")\n    \n    with col2:\n        volume_lower = statistics['ci_lower'] * project_info['total_area']\n        st.metric(\"Volume M√≠nimo IC 90% (m¬≥)\", f\"{volume_lower:.2f}\")\n    \n    with col3:\n        volume_upper = statistics['ci_upper'] * project_info['total_area']\n        st.metric(\"Volume M√°ximo IC 90% (m¬≥)\", f\"{volume_upper:.2f}\")\n\ndef report_tab():\n    st.header(\"üìë Relat√≥rio Final\")\n    \n    if not st.session_state.data_processed:\n        st.warning(\"‚ö†Ô∏è Primeiro fa√ßa o upload e processamento dos dados na aba 'Upload de Dados'\")\n        return\n    \n    # Generate report\n    report_generator = ReportGenerator()\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        if st.button(\"üìä Gerar Relat√≥rio Excel\", type=\"primary\"):\n            excel_buffer = report_generator.generate_excel_report(\n                st.session_state.results_df,\n                st.session_state.statistics,\n                st.session_state.project_info\n            )\n            \n            st.download_button(\n                label=\"‚¨áÔ∏è Download Relat√≥rio Excel\",\n                data=excel_buffer,\n                file_name=f\"relatorio_inventario_{st.session_state.project_info['project_name'].replace(' ', '_')}.xlsx\",\n                mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n            )\n    \n    with col2:\n        if st.button(\"üìÑ Gerar Relat√≥rio PDF\", type=\"secondary\"):\n            pdf_buffer = report_generator.generate_pdf_report(\n                st.session_state.results_df,\n                st.session_state.statistics,\n                st.session_state.project_info\n            )\n            \n            st.download_button(\n                label=\"‚¨áÔ∏è Download Relat√≥rio PDF\",\n                data=pdf_buffer,\n                file_name=f\"relatorio_inventario_{st.session_state.project_info['project_name'].replace(' ', '_')}.pdf\",\n                mime=\"application/pdf\"\n            )\n    \n    # Display summary report\n    st.subheader(\"Resumo do Relat√≥rio\")\n    \n    project_info = st.session_state.project_info\n    statistics = st.session_state.statistics\n    results_df = st.session_state.results_df\n    \n    st.markdown(f\"\"\"\n    ### üìã Informa√ß√µes Gerais\n    - **Projeto:** {project_info['project_name']}\n    - **N√∫mero de Parcelas:** {project_info['num_plots']}\n    - **√Årea por Parcela:** {project_info['plot_area']:.4f} ha\n    - **√Årea Total Amostrada:** {project_info['total_sampled_area']:.4f} ha\n    - **√Årea de Supress√£o:** {project_info['total_area']:.2f} ha\n    - **Porcentagem Amostrada:** {project_info['sampling_percentage']:.2f}%\n    - **Fator de Forma:** {project_info['form_factor']:.2f}\n    \n    ### üìä Resultados Estat√≠sticos\n    - **Total de √Årvores:** {len(results_df)}\n    - **Volume M√©dio:** {statistics['mean']:.4f} m¬≥/ha\n    - **Desvio Padr√£o:** {statistics['std_dev']:.4f} m¬≥/ha\n    - **Erro Amostral:** {statistics['sampling_error']:.2f}%\n    - **Intervalo de Confian√ßa 90%:** {statistics['ci_lower']:.4f} - {statistics['ci_upper']:.4f} m¬≥/ha\n    \n    ### üéØ Avalia√ß√£o da Precis√£o\n    \"\"\")\n    \n    if statistics['sampling_error'] > 20:\n        st.markdown(\"üî¥ **Amostragem n√£o atingiu a precis√£o desejada (erro > 20%). Recomendado aumentar o n√∫mero de parcelas.**\")\n    else:\n        st.markdown(\"üü¢ **Amostragem atingiu a precis√£o desejada (erro ‚â§ 20%).**\")\n    \n    volume_estimate = statistics['mean'] * project_info['total_area']\n    st.markdown(f\"\"\"\n    ### üìà Estimativa Final de Volume\n    - **Volume Total Estimado:** {volume_estimate:.2f} m¬≥\n    - **Volume M√≠nimo (IC 90%):** {statistics['ci_lower'] * project_info['total_area']:.2f} m¬≥\n    - **Volume M√°ximo (IC 90%):** {statistics['ci_upper'] * project_info['total_area']:.2f} m¬≥\n    \"\"\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":20570},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"numpy>=2.3.2\",\n    \"openpyxl>=3.1.5\",\n    \"pandas>=2.3.1\",\n    \"reportlab>=4.4.3\",\n    \"scipy>=1.16.1\",\n    \"streamlit>=1.48.1\",\n]\n","size_bytes":278},"replit.md":{"content":"# Sistema de Invent√°rio Florestal\n\n## Overview\n\nThis is a forest inventory analysis system built with Streamlit that processes field data to calculate forest volume measurements and generate comprehensive statistical reports. The system allows users to upload field measurement data (tree circumference, height, species) and automatically calculates volumes, statistics, and generates professional reports in Excel and PDF formats. It's designed for forestry professionals conducting forest inventories and suppression assessments.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Frontend Architecture\n- **Framework**: Streamlit web application with a tabbed interface\n- **UI Structure**: Four main tabs for data upload, processing, statistics, and reporting\n- **State Management**: Session state variables to maintain data persistence across tab interactions\n- **Layout**: Wide layout with responsive columns for better data presentation\n\n### Backend Architecture\n- **Modular Design**: Separated into utility modules for specific functions:\n  - `ForestryCalculator`: Handles all forestry-specific calculations (DAP, tree volume, volume per hectare)\n  - `StatisticsAnalyzer`: Performs statistical analysis including confidence intervals and sampling error\n  - `ReportGenerator`: Creates Excel and PDF reports with multiple sheets/sections\n- **Data Processing**: Pandas-based data manipulation for handling uploaded CSV/Excel files\n- **Mathematical Engine**: NumPy for numerical calculations and SciPy for statistical computations\n\n### Calculation Engine\n- **Forestry Formulas**: Implements specific forestry equations:\n  - DAP calculation from circumference (DAP = CAP/œÄ)\n  - Tree volume using allometric equation: VT = 0.000094 √ó (DAP^1.830398) √ó (HT^0.960913)\n  - Volume per hectare calculations with form factor adjustments\n- **Statistical Analysis**: Comprehensive statistics including mean, variance, coefficient of variation, confidence intervals, and sampling error calculations\n\n### Report Generation\n- **Excel Reports**: Multi-sheet workbooks using openpyxl engine with project info, detailed calculations, statistics, and volume summaries\n- **PDF Reports**: Professional reports using ReportLab with structured layouts, tables, and formatting\n- **Data Export**: In-memory buffer generation for file downloads without server storage\n\n## External Dependencies\n\n### Core Libraries\n- **Streamlit**: Web application framework for the user interface\n- **Pandas**: Data manipulation and analysis for handling forest inventory datasets\n- **NumPy**: Numerical computing for mathematical calculations\n- **SciPy**: Statistical functions for confidence interval calculations\n\n### Report Generation\n- **openpyxl**: Excel file creation and manipulation for detailed spreadsheet reports\n- **ReportLab**: PDF generation library for professional report formatting\n\n### Data Processing\n- **io**: In-memory file handling for upload/download operations without disk storage\n- **datetime**: Timestamp generation for report metadata\n\n### Statistical Analysis\n- **scipy.stats**: Statistical distributions and hypothesis testing for forestry sample analysis\n\nThe system follows a clean separation of concerns with dedicated modules for calculations, statistics, and reporting, making it maintainable and extensible for additional forestry analysis features.","size_bytes":3408},"utils/calculations.py":{"content":"import pandas as pd\nimport numpy as np\n\nclass ForestryCalculator:\n    \"\"\"Class for performing forestry calculations according to the specified formulas.\"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def calculate_dap(self, cap):\n        \"\"\"\n        Calculate DAP (Diameter at Breast Height) from CAP (Circumference at Breast Height).\n        Formula: DAP = CAP / œÄ\n        \n        Args:\n            cap (float): Circumference at breast height in cm\n            \n        Returns:\n            float: Diameter at breast height in cm (mant√©m em cm para usar na f√≥rmula VT)\n        \"\"\"\n        return cap / np.pi  # DAP em cm\n    \n    def calculate_tree_volume(self, dap_cm, ht):\n        \"\"\"\n        Calculate tree volume using the exact formula provided by user.\n        Formula: VT = 0,000094 √ó DAP^1,830398 √ó HT^0,960913\n        \n        Args:\n            dap_cm (float): Diameter at breast height in cm (conforme f√≥rmula)\n            ht (float): Total height in meters\n            \n        Returns:\n            float: Tree volume in cubic meters\n        \"\"\"\n        return 0.000094 * (dap_cm ** 1.830398) * (ht ** 0.960913)\n    \n    def calculate_volume_per_hectare(self, tree_volume, form_factor, plot_area_ha):\n        \"\"\"\n        Calculate volume per hectare.\n        Formula: VT_ha = (VT / FF) / plot_area_ha\n        \n        Args:\n            tree_volume (float): Tree volume in cubic meters\n            form_factor (float): Form factor\n            plot_area_ha (float): Plot area in hectares\n            \n        Returns:\n            float: Volume per hectare in cubic meters per hectare\n        \"\"\"\n        return (tree_volume / form_factor) / plot_area_ha\n    \n    def calculate_stereo_volume(self, volume_per_ha):\n        \"\"\"\n        Calculate stereo volume per hectare.\n        Formula: VT_st/ha = VT_ha √ó 2.65\n        \n        Args:\n            volume_per_ha (float): Volume per hectare in cubic meters\n            \n        Returns:\n            float: Stereo volume per hectare\n        \"\"\"\n        return volume_per_ha * 2.65\n    \n    def process_data(self, df, form_factor, plot_area_ha):\n        \"\"\"\n        Process the complete dataset with all forestry calculations.\n        \n        Args:\n            df (pandas.DataFrame): Input dataframe with tree data\n            form_factor (float): Form factor for calculations\n            plot_area_ha (float): Plot area in hectares\n            \n        Returns:\n            pandas.DataFrame: Processed dataframe with all calculations\n        \"\"\"\n        import streamlit as st\n        \n        initial_count = len(df)\n        st.write(f\"**Iniciando processamento com {initial_count} √°rvores**\")\n        \n        # Apply column mapping first\n        results_df = self._apply_column_mapping(df.copy())\n        st.write(f\"**Ap√≥s mapeamento: {len(results_df)} √°rvores**\")\n        \n        # Validate required columns\n        required_columns = ['CAP (cm)', 'HT (m)']\n        for col in required_columns:\n            if col not in results_df.columns:\n                raise ValueError(f\"Required column '{col}' not found in data\")\n        \n        # Check for missing values before removing them\n        missing_cap = results_df['CAP (cm)'].isna().sum()\n        missing_ht = results_df['HT (m)'].isna().sum()\n        if missing_cap > 0 or missing_ht > 0:\n            st.warning(f\"Valores vazios encontrados: CAP={missing_cap}, HT={missing_ht}\")\n        \n        # Remove rows with missing values in critical columns\n        before_dropna = len(results_df)\n        \n        # Identificar linhas com dados vazios antes de remover\n        empty_rows = results_df[results_df[required_columns].isna().any(axis=1)]\n        if len(empty_rows) > 0:\n            st.write(\"**Linhas com dados vazios que ser√£o removidas:**\")\n            if 'N¬∫ da √°rvore' in empty_rows.columns:\n                tree_numbers = empty_rows['N¬∫ da √°rvore'].tolist()\n                st.write(f\"√Årvores: {tree_numbers}\")\n            st.dataframe(empty_rows[required_columns + (['N¬∫ da √°rvore'] if 'N¬∫ da √°rvore' in empty_rows.columns else [])].head(10))\n        \n        results_df = results_df.dropna(subset=required_columns)\n        after_dropna = len(results_df)\n        if before_dropna > after_dropna:\n            st.write(f\"**Ap√≥s remover linhas vazias: {after_dropna} √°rvores (-{before_dropna-after_dropna})**\")\n        \n        # Convert to numeric and check for conversion errors\n        cap_before = len(results_df)\n        results_df['CAP (cm)'] = pd.to_numeric(results_df['CAP (cm)'], errors='coerce')\n        results_df['HT (m)'] = pd.to_numeric(results_df['HT (m)'], errors='coerce')\n        \n        # Check how many became NaN after conversion\n        invalid_cap = results_df['CAP (cm)'].isna().sum()\n        invalid_ht = results_df['HT (m)'].isna().sum()\n        if invalid_cap > 0 or invalid_ht > 0:\n            st.warning(f\"Valores n√£o num√©ricos encontrados: CAP={invalid_cap}, HT={invalid_ht}\")\n            \n            # Show some examples of invalid data\n            invalid_rows = results_df[results_df['CAP (cm)'].isna() | results_df['HT (m)'].isna()]\n            if len(invalid_rows) > 0:\n                st.write(\"Exemplos de dados inv√°lidos:\")\n                st.dataframe(invalid_rows[['CAP (cm)', 'HT (m)']].head())\n        \n        # Identificar linhas com dados n√£o num√©ricos antes de remover\n        invalid_rows = results_df[results_df['CAP (cm)'].isna() | results_df['HT (m)'].isna()]\n        if len(invalid_rows) > 0:\n            st.write(\"**Linhas com dados n√£o num√©ricos que ser√£o removidas:**\")\n            if 'N¬∫ da √°rvore' in invalid_rows.columns:\n                tree_numbers = invalid_rows['N¬∫ da √°rvore'].tolist()\n                st.write(f\"√Årvores com dados inv√°lidos: {tree_numbers}\")\n            st.dataframe(invalid_rows[['CAP (cm)', 'HT (m)'] + (['N¬∫ da √°rvore'] if 'N¬∫ da √°rvore' in invalid_rows.columns else [])].head(10))\n        \n        # Remove rows with invalid numeric values\n        before_numeric_filter = len(results_df)\n        results_df = results_df.dropna(subset=['CAP (cm)', 'HT (m)'])\n        after_numeric_filter = len(results_df)\n        \n        if before_numeric_filter > after_numeric_filter:\n            st.write(f\"**Ap√≥s remover dados n√£o num√©ricos: {after_numeric_filter} √°rvores (-{before_numeric_filter-after_numeric_filter})**\")\n        \n        # Calculate DAP in centimeters (conforme f√≥rmula)\n        results_df['DAP (cm)'] = results_df['CAP (cm)'].apply(self.calculate_dap)\n        \n        # Calculate tree volume using DAP in cm and HT in meters\n        results_df['VT (m¬≥)'] = results_df.apply(\n            lambda row: self.calculate_tree_volume(row['DAP (cm)'], row['HT (m)']),\n            axis=1\n        )\n        \n        # Calculate volume per hectare\n        results_df['VT (m¬≥/ha)'] = results_df['VT (m¬≥)'].apply(\n            lambda vt: self.calculate_volume_per_hectare(vt, form_factor, plot_area_ha)\n        )\n        \n        # Calculate stereo volume per hectare\n        results_df['VT (st/ha)'] = results_df['VT (m¬≥/ha)'].apply(self.calculate_stereo_volume)\n        \n        # Round all calculated values to 4 decimal places for precision\n        calculation_columns = ['DAP (cm)', 'VT (m¬≥)', 'VT (m¬≥/ha)', 'VT (st/ha)']\n        for col in calculation_columns:\n            results_df[col] = results_df[col].round(4)\n        \n        final_count = len(results_df)\n        st.success(f\"**Processamento conclu√≠do: {final_count} √°rvores processadas de {initial_count} originais**\")\n        \n        if final_count < initial_count:\n            st.error(f\"‚ùå PERDA TOTAL: {initial_count - final_count} √°rvores foram removidas durante o processamento\")\n        \n        return results_df\n    \n    def validate_input_data(self, df):\n        \"\"\"\n        Validate the input data for common issues.\n        \n        Args:\n            df (pandas.DataFrame): Input dataframe to validate\n            \n        Returns:\n            list: List of validation errors\n        \"\"\"\n        errors = []\n        \n        # Apply column mapping first\n        df = self._apply_column_mapping(df)\n        \n        # Check for required columns\n        required_columns = ['N¬∫ da √°rvore', 'Nome comum/cient√≠fico', 'CAP (cm)', 'HT (m)']\n        missing_columns = [col for col in required_columns if col not in df.columns]\n        if missing_columns:\n            errors.append(f\"Colunas obrigat√≥rias n√£o encontradas: {', '.join(missing_columns)}\")\n        \n        # Check for empty dataframe\n        if len(df) == 0:\n            errors.append(\"Planilha vazia ou sem dados v√°lidos\")\n        \n        # Check for numeric values in CAP and HT columns\n        if 'CAP (cm)' in df.columns:\n            non_numeric_cap = df['CAP (cm)'].apply(lambda x: not pd.api.types.is_numeric_dtype(type(x)) and pd.notna(x))\n            if non_numeric_cap.any():\n                errors.append(\"Valores n√£o num√©ricos encontrados na coluna CAP (cm)\")\n        \n        if 'HT (m)' in df.columns:\n            non_numeric_ht = df['HT (m)'].apply(lambda x: not pd.api.types.is_numeric_dtype(type(x)) and pd.notna(x))\n            if non_numeric_ht.any():\n                errors.append(\"Valores n√£o num√©ricos encontrados na coluna HT (m)\")\n        \n        # Check for negative values\n        if 'CAP (cm)' in df.columns:\n            negative_cap = df['CAP (cm)'] <= 0\n            if negative_cap.any():\n                errors.append(\"Valores negativos ou zero encontrados na coluna CAP (cm)\")\n        \n        if 'HT (m)' in df.columns:\n            negative_ht = df['HT (m)'] <= 0\n            if negative_ht.any():\n                errors.append(\"Valores negativos ou zero encontrados na coluna HT (m)\")\n        \n        return errors\n    \n    def _apply_column_mapping(self, df):\n        \"\"\"\n        Apply column name mapping to handle different column name formats.\n        \n        Args:\n            df (pandas.DataFrame): Input dataframe\n            \n        Returns:\n            pandas.DataFrame: Dataframe with mapped column names\n        \"\"\"\n        df = df.copy()\n        \n        # Map column names to expected format\n        column_mapping = {\n            'N¬∞': 'N¬∫ da √°rvore',\n            'NOME COMUM': 'Nome comum/cient√≠fico',\n            'NOME CIENT√çFICO': 'Nome cient√≠fico',\n            'CAP (cm)': 'CAP (cm)',\n            'HT(m)': 'HT (m)',\n            'Altura total HT(m)': 'HT (m)'\n        }\n        \n        # Rename columns if they exist with different names\n        for old_name, new_name in column_mapping.items():\n            if old_name in df.columns:\n                df = df.rename(columns={old_name: new_name})\n        \n        # Combine nome comum and cient√≠fico if they are separate\n        if 'Nome comum/cient√≠fico' not in df.columns:\n            if 'NOME COMUM' in df.columns and 'NOME CIENT√çFICO' in df.columns:\n                df['Nome comum/cient√≠fico'] = df['NOME COMUM'].astype(str) + ' / ' + df['NOME CIENT√çFICO'].astype(str)\n            elif 'NOME COMUM' in df.columns:\n                df['Nome comum/cient√≠fico'] = df['NOME COMUM']\n            elif 'NOME CIENT√çFICO' in df.columns:\n                df['Nome comum/cient√≠fico'] = df['NOME CIENT√çFICO']\n        \n        return df\n","size_bytes":11258},"utils/report_generator.py":{"content":"import pandas as pd\nimport io\nfrom datetime import datetime\nfrom reportlab.lib.pagesizes import letter, A4\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.lib.units import inch\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\nfrom reportlab.lib import colors\nfrom reportlab.lib.enums import TA_CENTER, TA_LEFT\n\nclass ReportGenerator:\n    \"\"\"Class for generating Excel and PDF reports from forest inventory analysis.\"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def generate_excel_report(self, results_df, statistics, project_info):\n        \"\"\"\n        Generate a comprehensive Excel report.\n        \n        Args:\n            results_df (pandas.DataFrame): Processed data with calculations\n            statistics (dict): Statistical analysis results\n            project_info (dict): Project information\n            \n        Returns:\n            io.BytesIO: Excel file buffer\n        \"\"\"\n        buffer = io.BytesIO()\n        \n        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:\n            # Sheet 1: Project Information\n            self._create_project_info_sheet(writer, project_info, statistics)\n            \n            # Sheet 2: Detailed calculations\n            results_df.to_excel(writer, sheet_name='C√°lculos Detalhados', index=False)\n            \n            # Sheet 3: Statistical Summary\n            self._create_statistics_sheet(writer, statistics, project_info)\n            \n            # Sheet 4: Volume Summary\n            self._create_volume_summary_sheet(writer, results_df, project_info, statistics)\n        \n        buffer.seek(0)\n        return buffer.getvalue()\n    \n    def _create_project_info_sheet(self, writer, project_info, statistics):\n        \"\"\"Create project information sheet.\"\"\"\n        project_data = {\n            'Par√¢metro': [\n                'Nome do Projeto',\n                'Data do Relat√≥rio',\n                'N√∫mero de Parcelas',\n                'Dimens√µes da Parcela (m)',\n                '√Årea por Parcela (ha)',\n                '√Årea Total Amostrada (ha)',\n                '√Årea de Supress√£o (ha)',\n                'Porcentagem Amostrada (%)',\n                'Fator de Forma',\n                'Total de √Årvores',\n                'Erro Amostral (%)',\n                'Precis√£o Atingida'\n            ],\n            'Valor': [\n                project_info['project_name'],\n                datetime.now().strftime('%d/%m/%Y %H:%M'),\n                project_info['num_plots'],\n                f\"{project_info['plot_length']} x {project_info['plot_width']}\",\n                f\"{project_info['plot_area']:.4f}\",\n                f\"{project_info['total_sampled_area']:.4f}\",\n                f\"{project_info['total_area']:.2f}\",\n                f\"{project_info['sampling_percentage']:.2f}\",\n                f\"{project_info['form_factor']:.2f}\",\n                statistics['n_trees'],\n                f\"{statistics['sampling_error']:.2f}\",\n                'Sim' if statistics['sampling_error'] <= 20 else 'N√£o'\n            ]\n        }\n        \n        project_df = pd.DataFrame(project_data)\n        project_df.to_excel(writer, sheet_name='Informa√ß√µes do Projeto', index=False)\n    \n    def _create_statistics_sheet(self, writer, statistics, project_info):\n        \"\"\"Create statistical analysis sheet.\"\"\"\n        stats_data = {\n            'Estat√≠stica': [\n                'N√∫mero de √Årvores',\n                'M√©dia (m¬≥/ha)',\n                'Vari√¢ncia',\n                'Desvio Padr√£o',\n                'Coeficiente de Varia√ß√£o (%)',\n                'Erro Padr√£o',\n                'Limite Inferior IC 90%',\n                'Limite Superior IC 90%',\n                'Erro Amostral (%)',\n                'Valor M√≠nimo',\n                'Valor M√°ximo',\n                'Mediana',\n                't cr√≠tico',\n                'Margem de Erro'\n            ],\n            'Valor': [\n                statistics['n_trees'],\n                statistics['mean'],\n                statistics['variance'],\n                statistics['std_dev'],\n                statistics['cv'],\n                statistics['standard_error'],\n                statistics['ci_lower'],\n                statistics['ci_upper'],\n                statistics['sampling_error'],\n                statistics['minimum'],\n                statistics['maximum'],\n                statistics['median'],\n                statistics['t_critical'],\n                statistics['margin_of_error']\n            ]\n        }\n        \n        stats_df = pd.DataFrame(stats_data)\n        stats_df.to_excel(writer, sheet_name='An√°lise Estat√≠stica', index=False)\n    \n    def _create_volume_summary_sheet(self, writer, results_df, project_info, statistics):\n        \"\"\"Create volume summary sheet.\"\"\"\n        # Calculate volume estimates for total area\n        volume_estimate = statistics['mean'] * project_info['total_area']\n        volume_lower = statistics['ci_lower'] * project_info['total_area']\n        volume_upper = statistics['ci_upper'] * project_info['total_area']\n        \n        # Calculate stereo volumes\n        stereo_mean = results_df['VT (st/ha)'].mean()\n        stereo_estimate = stereo_mean * project_info['total_area']\n        \n        volume_data = {\n            'Tipo de Volume': [\n                'Volume M√©dio por Hectare (m¬≥/ha)',\n                'Volume Total Estimado (m¬≥)',\n                'Volume M√≠nimo IC 90% (m¬≥)',\n                'Volume M√°ximo IC 90% (m¬≥)',\n                'Volume M√©dio Est√©reo por Hectare (st/ha)',\n                'Volume Total Est√©reo Estimado (st)',\n                'Volume Total das √Årvores Amostradas (m¬≥)',\n                'N√∫mero Total de √Årvores Amostradas'\n            ],\n            'Valor': [\n                f\"{statistics['mean']:.4f}\",\n                f\"{volume_estimate:.2f}\",\n                f\"{volume_lower:.2f}\",\n                f\"{volume_upper:.2f}\",\n                f\"{stereo_mean:.4f}\",\n                f\"{stereo_estimate:.2f}\",\n                f\"{results_df['VT (m¬≥)'].sum():.4f}\",\n                len(results_df)\n            ]\n        }\n        \n        volume_df = pd.DataFrame(volume_data)\n        volume_df.to_excel(writer, sheet_name='Resumo de Volumes', index=False)\n    \n    def generate_pdf_report(self, results_df, statistics, project_info):\n        \"\"\"\n        Generate a comprehensive PDF report.\n        \n        Args:\n            results_df (pandas.DataFrame): Processed data with calculations\n            statistics (dict): Statistical analysis results\n            project_info (dict): Project information\n            \n        Returns:\n            io.BytesIO: PDF file buffer\n        \"\"\"\n        buffer = io.BytesIO()\n        doc = SimpleDocTemplate(buffer, pagesize=A4)\n        story = []\n        \n        # Styles\n        styles = getSampleStyleSheet()\n        title_style = ParagraphStyle(\n            'CustomTitle',\n            parent=styles['Title'],\n            fontSize=18,\n            spaceAfter=30,\n            alignment=TA_CENTER\n        )\n        \n        heading_style = ParagraphStyle(\n            'CustomHeading',\n            parent=styles['Heading1'],\n            fontSize=14,\n            spaceAfter=12,\n            spaceBefore=20\n        )\n        \n        # Title\n        story.append(Paragraph(\"Relat√≥rio de Invent√°rio Florestal\", title_style))\n        story.append(Spacer(1, 20))\n        \n        # Project Information\n        story.append(Paragraph(\"Informa√ß√µes do Projeto\", heading_style))\n        project_table_data = [\n            ['Par√¢metro', 'Valor'],\n            ['Nome do Projeto', project_info['project_name']],\n            ['Data do Relat√≥rio', datetime.now().strftime('%d/%m/%Y %H:%M')],\n            ['N√∫mero de Parcelas', str(project_info['num_plots'])],\n            ['Dimens√µes da Parcela', f\"{project_info['plot_length']} x {project_info['plot_width']} m\"],\n            ['√Årea por Parcela', f\"{project_info['plot_area']:.4f} ha\"],\n            ['√Årea Total Amostrada', f\"{project_info['total_sampled_area']:.4f} ha\"],\n            ['√Årea de Supress√£o', f\"{project_info['total_area']:.2f} ha\"],\n            ['Porcentagem Amostrada', f\"{project_info['sampling_percentage']:.2f}%\"],\n            ['Fator de Forma', f\"{project_info['form_factor']:.2f}\"],\n        ]\n        \n        project_table = Table(project_table_data)\n        project_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, 0), 12),\n            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black)\n        ]))\n        \n        story.append(project_table)\n        story.append(Spacer(1, 20))\n        \n        # Statistical Analysis\n        story.append(Paragraph(\"An√°lise Estat√≠stica\", heading_style))\n        stats_table_data = [\n            ['Estat√≠stica', 'Valor'],\n            ['N√∫mero de √Årvores', str(statistics['n_trees'])],\n            ['M√©dia (m¬≥/ha)', f\"{statistics['mean']:.4f}\"],\n            ['Desvio Padr√£o', f\"{statistics['std_dev']:.4f}\"],\n            ['Coeficiente de Varia√ß√£o (%)', f\"{statistics['cv']:.2f}\"],\n            ['Erro Amostral (%)', f\"{statistics['sampling_error']:.2f}\"],\n            ['Intervalo de Confian√ßa 90%', f\"{statistics['ci_lower']:.4f} - {statistics['ci_upper']:.4f}\"],\n        ]\n        \n        stats_table = Table(stats_table_data)\n        stats_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, 0), 12),\n            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black)\n        ]))\n        \n        story.append(stats_table)\n        story.append(Spacer(1, 20))\n        \n        # Precision Assessment\n        story.append(Paragraph(\"Avalia√ß√£o da Precis√£o\", heading_style))\n        if statistics['sampling_error'] <= 20:\n            precision_text = f\"‚úì Amostragem atingiu a precis√£o desejada (erro {statistics['sampling_error']:.2f}% ‚â§ 20%).\"\n        else:\n            precision_text = f\"‚ö† Amostragem n√£o atingiu a precis√£o desejada (erro {statistics['sampling_error']:.2f}% > 20%). Recomendado aumentar o n√∫mero de parcelas.\"\n        \n        story.append(Paragraph(precision_text, styles['Normal']))\n        story.append(Spacer(1, 20))\n        \n        # Volume Estimates\n        story.append(Paragraph(\"Estimativas de Volume\", heading_style))\n        volume_estimate = statistics['mean'] * project_info['total_area']\n        volume_lower = statistics['ci_lower'] * project_info['total_area']\n        volume_upper = statistics['ci_upper'] * project_info['total_area']\n        \n        volume_table_data = [\n            ['Tipo de Estimativa', 'Valor'],\n            ['Volume Total Estimado (m¬≥)', f\"{volume_estimate:.2f}\"],\n            ['Volume M√≠nimo IC 90% (m¬≥)', f\"{volume_lower:.2f}\"],\n            ['Volume M√°ximo IC 90% (m¬≥)', f\"{volume_upper:.2f}\"],\n        ]\n        \n        volume_table = Table(volume_table_data)\n        volume_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, 0), 12),\n            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black)\n        ]))\n        \n        story.append(volume_table)\n        \n        # Build PDF\n        doc.build(story)\n        buffer.seek(0)\n        return buffer.getvalue()\n","size_bytes":12162},"utils/statistics.py":{"content":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nclass StatisticsAnalyzer:\n    \"\"\"Class for performing statistical analysis on forest inventory data.\"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def calculate_statistics(self, results_df, project_info):\n        \"\"\"\n        Calculate comprehensive statistics for the forest inventory data.\n        \n        Args:\n            results_df (pandas.DataFrame): Processed dataframe with volume calculations\n            project_info (dict): Project information including plot details\n            \n        Returns:\n            dict: Dictionary containing all statistical measures\n        \"\"\"\n        # Use volume per hectare for statistical analysis\n        volume_data = results_df['VT (m¬≥/ha)']\n        n = len(volume_data)\n        \n        # Basic descriptive statistics\n        mean = volume_data.mean()\n        variance = volume_data.var(ddof=1)  # Sample variance\n        std_dev = volume_data.std(ddof=1)   # Sample standard deviation\n        \n        # Coefficient of variation\n        cv = (std_dev / mean) * 100 if mean != 0 else 0\n        \n        # Standard error of the mean\n        standard_error = std_dev / np.sqrt(n)\n        \n        # 90% Confidence interval\n        confidence_level = 0.90\n        alpha = 1 - confidence_level\n        t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n        \n        margin_of_error = t_critical * standard_error\n        ci_lower = mean - margin_of_error\n        ci_upper = mean + margin_of_error\n        \n        # Sampling error (as percentage of the mean)\n        sampling_error = (margin_of_error / mean) * 100 if mean != 0 else 0\n        \n        # Additional statistics\n        minimum = volume_data.min()\n        maximum = volume_data.max()\n        median = volume_data.median()\n        \n        # Calculate expansion factors\n        plot_area = project_info['plot_area']\n        total_area = project_info['total_area']\n        expansion_factor = total_area / (plot_area * project_info['num_plots'])\n        \n        statistics = {\n            'n_trees': n,\n            'mean': round(mean, 4),\n            'variance': round(variance, 4),\n            'std_dev': round(std_dev, 4),\n            'cv': round(cv, 2),\n            'standard_error': round(standard_error, 4),\n            'ci_lower': round(ci_lower, 4),\n            'ci_upper': round(ci_upper, 4),\n            'sampling_error': round(sampling_error, 2),\n            'minimum': round(minimum, 4),\n            'maximum': round(maximum, 4),\n            'median': round(median, 4),\n            't_critical': round(t_critical, 4),\n            'margin_of_error': round(margin_of_error, 4),\n            'expansion_factor': round(expansion_factor, 4),\n            'confidence_level': confidence_level\n        }\n        \n        return statistics\n    \n    def assess_sampling_precision(self, sampling_error, threshold=20.0):\n        \"\"\"\n        Assess whether the sampling meets precision requirements.\n        \n        Args:\n            sampling_error (float): Sampling error as percentage\n            threshold (float): Precision threshold (default 20%)\n            \n        Returns:\n            dict: Assessment results\n        \"\"\"\n        meets_precision = sampling_error <= threshold\n        \n        assessment = {\n            'meets_precision': meets_precision,\n            'sampling_error': sampling_error,\n            'threshold': threshold,\n            'message': self._get_precision_message(meets_precision, sampling_error)\n        }\n        \n        return assessment\n    \n    def _get_precision_message(self, meets_precision, sampling_error):\n        \"\"\"\n        Get appropriate message based on precision assessment.\n        \n        Args:\n            meets_precision (bool): Whether precision requirement is met\n            sampling_error (float): Sampling error percentage\n            \n        Returns:\n            str: Appropriate message\n        \"\"\"\n        if meets_precision:\n            return f\"Amostragem atingiu a precis√£o desejada (erro {sampling_error:.2f}% ‚â§ 20%).\"\n        else:\n            return f\"Amostragem n√£o atingiu a precis√£o desejada (erro {sampling_error:.2f}% > 20%). Recomendado aumentar o n√∫mero de parcelas.\"\n    \n    def calculate_required_plots(self, current_error, target_error=20.0, current_plots=1):\n        \"\"\"\n        Calculate the number of plots required to achieve target precision.\n        \n        Args:\n            current_error (float): Current sampling error percentage\n            target_error (float): Target sampling error percentage\n            current_plots (int): Current number of plots\n            \n        Returns:\n            int: Required number of plots\n        \"\"\"\n        if current_error <= target_error:\n            return current_plots\n        \n        # The relationship between number of plots and error is inversely proportional to sqrt(n)\n        error_ratio = current_error / target_error\n        required_plots = int(np.ceil(current_plots * (error_ratio ** 2)))\n        \n        return required_plots\n    \n    def generate_volume_summary(self, results_df, project_info):\n        \"\"\"\n        Generate a comprehensive volume summary for the project.\n        \n        Args:\n            results_df (pandas.DataFrame): Processed dataframe with calculations\n            project_info (dict): Project information\n            \n        Returns:\n            dict: Volume summary statistics\n        \"\"\"\n        # Volume calculations\n        total_tree_volume = results_df['VT (m¬≥)'].sum()\n        mean_volume_per_ha = results_df['VT (m¬≥/ha)'].mean()\n        total_volume_per_ha = results_df['VT (m¬≥/ha)'].sum()\n        \n        # Stereo volume calculations\n        mean_stereo_volume_per_ha = results_df['VT (st/ha)'].mean()\n        total_stereo_volume_per_ha = results_df['VT (st/ha)'].sum()\n        \n        # Project-wide estimates\n        total_area = project_info['total_area']\n        estimated_total_volume = mean_volume_per_ha * total_area\n        estimated_total_stereo = mean_stereo_volume_per_ha * total_area\n        \n        summary = {\n            'total_tree_volume': round(total_tree_volume, 4),\n            'mean_volume_per_ha': round(mean_volume_per_ha, 4),\n            'total_volume_per_ha': round(total_volume_per_ha, 4),\n            'mean_stereo_volume_per_ha': round(mean_stereo_volume_per_ha, 4),\n            'total_stereo_volume_per_ha': round(total_stereo_volume_per_ha, 4),\n            'estimated_total_volume': round(estimated_total_volume, 2),\n            'estimated_total_stereo': round(estimated_total_stereo, 2)\n        }\n        \n        return summary\n","size_bytes":6633}}}